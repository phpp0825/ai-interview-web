# evaluation.py
# Evaluate candidate responses via LLM and save evaluation results to a text file

import json
import logging
from typing import List

from .llm_client import LLMClient
from .config import LlamaConfig
from .stt import STTClient, calculate_silence_duration, calculate_audio_duration

logger = logging.getLogger(__name__)

def evaluate_and_save_responses(
    questions: List[str],
    answers: List[str],
    audio_files: List[str],
    output_file: str = "interview_evaluation.txt"
) -> list:
    """
    Evaluate user responses using an LLM and save structured results to a TXT file.
    ë¹ˆ ë‹µë³€ ë° 'ê·¸ë§Œí•˜ê² ìŠµë‹ˆë‹¤' íŠ¸ë¦¬ê±°ë¥¼ ê±´ë„ˆë›°ê³ ,
    ëª¨ë“  ì¶œë ¥ì€ í•œêµ­ì–´ë¡œë§Œ ì œê³µí•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ë¥¼ ì¡°ì •í•©ë‹ˆë‹¤.
    ê° í‰ê°€ í•­ëª©ì— ëŒ€í•´ ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ì´ì ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    llm_config = LlamaConfig()
    llm_client = LLMClient(llm_config)
    stt_client = STTClient()

    evaluations = []

    for idx, (question, answer, audio_path) in enumerate(zip(questions, answers, audio_files), start=1):
        # 1) 'ê·¸ë§Œí•˜ê² ìŠµë‹ˆë‹¤' ë©´ì ‘ ì¢…ë£Œ íŠ¸ë¦¬ê±° ê±´ë„ˆë›°ê¸°
        if answer.strip().lower() == "ê·¸ë§Œí•˜ê² ìŠµë‹ˆë‹¤":
            logger.info(f"Skipping evaluation for exit trigger at Q{idx}")
            break

        # 2) ë¹ˆ ë‹µë³€ì— ëŒ€í•´ì„œëŠ” LLM í˜¸ì¶œ ì—†ì´ ë‚®ì€ í‰ê°€ ì²˜ë¦¬
        if not answer.strip():
            try:
                total_time = calculate_audio_duration(audio_path)
                # ë¹ˆ ë‹µë³€ì˜ ê²½ìš° ì „ì²´ê°€ ì¹¨ë¬µìœ¼ë¡œ ê°„ì£¼
                silence = total_time
            except Exception as e:
                logger.warning(f"Audio duration calculation failed for {audio_path}: {e}")
                total_time = 0.0
                silence = 0.0
                
            evaluations.append({
                "question": question,
                "user_answer": "",
                "evaluation": {
                    "relevance":      {"rating": "ë‚®ìŒ", "comment": "ì‘ë‹µì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                    "completeness":   {"rating": "ë‚®ìŒ", "comment": "ì‘ë‹µì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                    "correctness":    {"rating": "ë‚®ìŒ", "comment": "ì‘ë‹µì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                    "clarity":        {"rating": "ë‚®ìŒ", "comment": "ì‘ë‹µì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                    "professionalism":{"rating": "ë‚®ìŒ", "comment": "ì‘ë‹µì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."},
                },
                "recommended_answer": "",
                "total_response_time": total_time,
                "silence_duration":    silence,
                "total_score": 0  # ë¹ˆ ë‹µë³€ì€ 0ì 
            })
            continue

        # 3) LLM í”„ë¡¬í”„íŠ¸: í•œêµ­ì–´ ê°•ì œ, JSON ì˜ˆì‹œë„ í•œê¸€í™”
        prompt = (
            "ëª¨ë“  ì¶œë ¥ì€ *ì˜¤ì§ í•œêµ­ì–´*ë¡œë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.\n"
            "ë‹¹ì‹ ì€ IT íšŒì‚¬ ë©´ì ‘ ì‘ë‹µì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì´ì ë©´ì ‘ í‰ê°€ í”„ë¡œê·¸ë¨ ê°œë°œìì…ë‹ˆë‹¤.\n"
            "ì•„ë˜ ë©´ì ‘ ì§ˆë¬¸ê³¼ ì§€ì›ìì˜ ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ë‹¤ì„¯ ê°€ì§€ ê¸°ì¤€ì— ë”°ë¼ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê³ ,"
            "ì¶”ì²œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.\n"
            "1. ê´€ë ¨ì„±: ë‹µë³€ì´ ì§ˆë¬¸ì˜ ìš”ì ì„ ì–¼ë§ˆë‚˜ ì˜ ë‹¤ë£¨ì—ˆëŠ”ê°€?\n"
            "2. ì™„ì „ì„±: ë‹µë³€ì— í•„ìš”í•œ ìš”ì†Œê°€ ì¶©ë¶„íˆ í¬í•¨ë˜ì—ˆëŠ”ê°€?\n"
            "3. ì •í™•ì„±: ì‚¬ì‹¤ì— ê¸°ë°˜í•œ ì •í™•í•œ ë‚´ìš©ì„ í¬í•¨í•˜ëŠ”ê°€?\n"
            "4. ëª…í™•ì„±: ì´í•´í•˜ê¸° ì‰½ê³  ë…¼ë¦¬ì ìœ¼ë¡œ êµ¬ì„±ë˜ì—ˆëŠ”ê°€?\n"
            "5. ì „ë¬¸ì„±: ë©´ì ‘ ë‹µë³€ìœ¼ë¡œì„œ ì ì ˆí•œ ì–´ì¡°ì™€ í‘œí˜„ì„ ì‚¬ìš©í–ˆëŠ”ê°€?\n\n"
            f"Question:\n{question}\n\n"
            f"Candidate's Answer:\n{answer}\n\n"
            "ì¶œë ¥ ì˜ˆì‹œ(ëª¨ë“  í‚¤ëŠ” ì˜ì–´, í‰ê°€ëŠ” í•œê¸€ë¡œ ì‘ì„±):\n"
            "{\n"
            '  "evaluation": {\n'
            '    "relevance":      {"rating": "ë†’ìŒ",   "comment": "..."},\n'
            '    "completeness":   {"rating": "ë³´í†µ",   "comment": "..."},\n'
            '    "correctness":    {"rating": "ë†’ìŒ",   "comment": "..."},\n'
            '    "clarity":        {"rating": "ë‚®ìŒ",   "comment": "..."},\n'
            '    "professionalism":{"rating": "ë†’ìŒ",   "comment": "..."}\n'
            "  },\n"
            '  "recommended_answer": "..." \n'
            "}\n"
        )

        # 4) LLM í˜¸ì¶œ ë° JSON íŒŒì‹±
        try:
            raw = llm_client.call(prompt)
            print(f"ğŸ” LLM ì›ì‹œ ì‘ë‹µ: {raw[:200]}...")
            data = json.loads(raw)
            eval_obj = data.get("evaluation", {})
            rec_answer = data.get("recommended_answer", "")
            print(f"âœ… JSON íŒŒì‹± ì„±ê³µ, evaluation íƒ€ì…: {type(eval_obj)}")
        except Exception as e:
            logger.error(f"LLM evaluation failed for question {idx}: {e}")
            print(f"âŒ LLM/JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ í‰ê°€ êµ¬ì¡° ì œê³µ
            eval_obj = {
                "relevance":      {"rating": "ë¶„ì„ë¶ˆê°€", "comment": "AI ë¶„ì„ ì˜¤ë¥˜ë¡œ í‰ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."},
                "completeness":   {"rating": "ë¶„ì„ë¶ˆê°€", "comment": "AI ë¶„ì„ ì˜¤ë¥˜ë¡œ í‰ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."},
                "correctness":    {"rating": "ë¶„ì„ë¶ˆê°€", "comment": "AI ë¶„ì„ ì˜¤ë¥˜ë¡œ í‰ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."},
                "clarity":        {"rating": "ë¶„ì„ë¶ˆê°€", "comment": "AI ë¶„ì„ ì˜¤ë¥˜ë¡œ í‰ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."},
                "professionalism":{"rating": "ë¶„ì„ë¶ˆê°€", "comment": "AI ë¶„ì„ ì˜¤ë¥˜ë¡œ í‰ê°€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."},
            }
            rec_answer = "AI ë¶„ì„ ì˜¤ë¥˜ë¡œ ì¶”ì²œ ë‹µë³€ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # === ì ìˆ˜ ê³„ì‚° ì¶”ê°€ ===
        total_score = calculate_score_from_evaluation(eval_obj)
        print(f"ğŸ“Š ê³„ì‚°ëœ ì ìˆ˜: {total_score}ì ")

        # 5) ì˜¤ë””ì˜¤ ì§€í‘œ ê³„ì‚°
        try:
            # STT ê²°ê³¼ì—ì„œ ì¹¨ë¬µ ì‹œê°„ ê³„ì‚° (ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„ í•„ìš”)
            stt_timestamps = stt_client.transcribe(audio_path)
            if stt_timestamps:
                silence = calculate_silence_duration(stt_timestamps)
            else:
                silence = 0.0
        except Exception as e:
            logger.warning(f"Silence calculation failed for {audio_path}: {e}")
            silence = 0.0

        try:
            total_time = calculate_audio_duration(audio_path)
        except Exception as e:
            logger.warning(f"Audio duration calculation failed for {audio_path}: {e}")
            total_time = 0.0

        evaluations.append({
            "question": question,
            "user_answer": answer,
            "evaluation": eval_obj,
            "recommended_answer": rec_answer,
            "total_response_time": total_time,
            "silence_duration": silence,
            "total_score": total_score  # ì´ì  ì¶”ê°€
        })

    # 6) íŒŒì¼ë¡œ ì¶œë ¥
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("ë©´ì ‘ í‰ê°€ ê²°ê³¼\n")
            f.write("=" * 50 + "\n\n")
            for i, item in enumerate(evaluations, start=1):
                # ì•ˆì „í•œ ë°ì´í„° ì¶”ì¶œ
                question = item.get('question', 'ì§ˆë¬¸ ì •ë³´ ì—†ìŒ')
                user_answer = item.get('user_answer', 'ë‹µë³€ ì •ë³´ ì—†ìŒ')
                recommended_answer = item.get('recommended_answer', 'ì¶”ì²œ ë‹µë³€ ì—†ìŒ')
                total_time = item.get('total_response_time', 0)
                silence = item.get('silence_duration', 0)
                total_score = item.get('total_score', 0)  # ì´ì  ê°€ì ¸ì˜¤ê¸°
                
                f.write(f"ì§ˆë¬¸ {i}:\n{question}\n\n")
                f.write(f"ì‚¬ìš©ì ë‹µë³€:\n{user_answer}\n\n")
                f.write("í‰ê°€ ê²°ê³¼:\n")
                
                # í‰ê°€ ë°ì´í„° ì•ˆì „ ì²˜ë¦¬
                evaluation_data = item.get("evaluation", {})
                try:
                    if isinstance(evaluation_data, dict):
                        for crit, res in evaluation_data.items():
                            try:
                                if isinstance(res, dict):
                                    rating = res.get('rating', 'ì •ë³´ì—†ìŒ')
                                    comment = res.get('comment', 'í‰ê°€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.')
                                    f.write(f"  {crit}: {rating} - {comment}\n")
                                elif isinstance(res, str):
                                    f.write(f"  {crit}: {res}\n")
                                else:
                                    f.write(f"  {crit}: {str(res)}\n")
                            except Exception as e:
                                f.write(f"  {crit}: í‰ê°€ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜ - {str(e)}\n")
                    else:
                        f.write(f"  í‰ê°€ ë°ì´í„° í˜•ì‹ ì˜¤ë¥˜: {type(evaluation_data)} - {str(evaluation_data)}\n")
                except Exception as e:
                    f.write(f"  í‰ê°€ ë°ì´í„° ì „ì²´ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}\n")
                
                f.write("\n")
                f.write(f"ì´ì : {total_score}ì \n")  # ì´ì  í‘œì‹œ ì¶”ê°€
                
                # ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ í‘œì‹œ
                if total_score >= 90:
                    grade = "A+ (ìš°ìˆ˜)"
                elif total_score >= 85:
                    grade = "A (ì¢‹ìŒ)"
                elif total_score >= 80:
                    grade = "B+ (ì–‘í˜¸)"
                elif total_score >= 75:
                    grade = "B (ë³´í†µ)"
                elif total_score >= 70:
                    grade = "C+ (ê°œì„  í•„ìš”)"
                else:
                    grade = "C (ë¯¸í¡)"
                
                f.write(f"ë“±ê¸‰: {grade}\n\n")
                f.write(f"ì¶”ì²œ ë‹µë³€:\n{recommended_answer}\n\n")
                f.write(f"ë‹µë³€ ì‹œê°„: {total_time} ì´ˆ\n")
                f.write(f"ì¹¨ë¬µ ì‹œê°„: {silence} ì´ˆ\n")
                f.write("\n" + "=" * 50 + "\n")
        logger.info(f"Evaluation results saved to {output_file}")
    except Exception as e:
        logger.error(f"Failed to write evaluation file {output_file}: {e}")
        print(f"âŒ íŒŒì¼ ì¶œë ¥ ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ê°€ ë°œìƒí•´ë„ ë¹ˆ íŒŒì¼ì´ë¼ë„ ìƒì„±í•˜ì—¬ í›„ì† ì²˜ë¦¬ê°€ ê°€ëŠ¥í•˜ë„ë¡ í•¨
        try:
            with open(output_file, "w", encoding="utf-8") as f:
                f.write("ë©´ì ‘ í‰ê°€ ê²°ê³¼\n")
                f.write("=" * 50 + "\n\n")
                f.write("í‰ê°€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n")
                f.write(f"ì˜¤ë¥˜ ë‚´ìš©: {str(e)}\n")
        except:
            pass
        # ì—¬ì „íˆ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚¤ì§€ë§Œ ë” ì•ˆì „í•œ í˜•íƒœë¡œ
        raise Exception(f"í‰ê°€ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {str(e)}")

    # 7) GUI/ë‹¤ë¥¸ í˜¸ì¶œìë¥¼ ìœ„í•´ í‰ê°€ ê²°ê³¼ ë°˜í™˜
    return evaluations

def calculate_score_from_evaluation(evaluation_obj):
    """
    í‰ê°€ ê²°ê³¼ì—ì„œ ìˆ«ì ì ìˆ˜ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    ê° í‰ê°€ í•­ëª©ì˜ ratingì„ ì ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ ì´ì ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    try:
        if not isinstance(evaluation_obj, dict):
            return 0
        
        # ê° í‰ê°€ í•­ëª©ë³„ ì ìˆ˜ ë§¤í•‘
        rating_scores = {
            "ë†’ìŒ": 20,     # ìš°ìˆ˜í•œ í‰ê°€
            "ë³´í†µ": 15,     # í‰ê· ì ì¸ í‰ê°€  
            "ë‚®ìŒ": 10,     # ë¶€ì¡±í•œ í‰ê°€
            "ë¶„ì„ë¶ˆê°€": 5   # ë¶„ì„ ì˜¤ë¥˜
        }
        
        total_score = 0
        evaluated_items = 0
        
        # 5ê°œ í‰ê°€ í•­ëª© ì ìˆ˜ ê³„ì‚°
        evaluation_criteria = ["relevance", "completeness", "correctness", "clarity", "professionalism"]
        
        for criterion in evaluation_criteria:
            if criterion in evaluation_obj:
                criterion_data = evaluation_obj[criterion]
                if isinstance(criterion_data, dict):
                    rating = criterion_data.get('rating', 'ë‚®ìŒ')
                    score = rating_scores.get(rating, 10)  # ê¸°ë³¸ê°’ 10ì 
                    total_score += score
                    evaluated_items += 1
                    print(f"  - {criterion}: {rating} ({score}ì )")
        
        # í‰ê· ì„ ë‚´ì–´ 100ì  ë§Œì ìœ¼ë¡œ ë³€í™˜
        if evaluated_items > 0:
            # ê° í•­ëª©ì´ 20ì ì”©ì´ë¯€ë¡œ ì´ 100ì  ë§Œì 
            final_score = min(100, total_score)  # ìµœëŒ€ 100ì ìœ¼ë¡œ ì œí•œ
        else:
            final_score = 0
            
        return final_score
        
    except Exception as e:
        print(f"âš ï¸ ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜: {e}")
        return 0
